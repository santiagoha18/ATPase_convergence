h2
# Venn diagram:
variants_list <- list(AncSR1 = c(x[x$BG=="AncSR1",]$AA_var,x[x$BG=="Both",]$AA_var),
AncSR2 = c(x[x$BG=="AncSR2",]$AA_var,x[x$BG=="Both",]$AA_var))
# Number of variants bound per ancestral background
#For each variant, if it is active on AncSR1, AncSR2 or both
x <- full_join(sr1_table,sr2_table,by="AA_var")%>%
mutate(BG = case_when(is.na(bg.x) == T ~ "AncSR2",
is.na(bg.y) == T ~ "AncSR1",
(is.na(bg.x) == F & is.na(bg.y) == F) ~ "Both")) %>%
select(AA_var,BG)
# Venn diagram:
variants_list <- list(AncSR1 = c(x[x$BG=="AncSR1",]$AA_var,x[x$BG=="Both",]$AA_var),
AncSR2 = c(x[x$BG=="AncSR2",]$AA_var,x[x$BG=="Both",]$AA_var))
ggvenn(variants_list,c("AncSR1","AncSR2"), fill_color = c("#0398fc","#fc9d03"),
stroke_size = 0.5, set_name_size = 4)
x
dim(active_vars[active_vars$meanF>=-3.714156,] %>% filter(.,grepl("AncSR1",REBC)))
# Number of variants bound per RE
# total variants bound per RE
counts <- rbind(sr1_table,sr2_table) %>% inner_join(.,x,by="AA_var") %>%
as_tibble() %>% filter(!(RE_annotation_S == "Promiscuous")) %>%
count(RE_annotation_S)
# Number of variants bound per RE
# total variants bound per RE
counts <- rbind(sr1_table,sr2_table) %>% inner_join(.,x,by="AA_var") %>%
as_tibble() %>% filter(.,!(RE_annotation_S == "Promiscuous")) %>%
count(RE_annotation_S)
# Number of variants bound per RE
# total variants bound per RE
counts <- rbind(sr1_table,sr2_table) %>% inner_join(.,x,by="AA_var") %>%
as_tibble() %>% dplyr::filter(.,!(RE_annotation_S == "Promiscuous")) %>%
count(RE_annotation_S)
rbind(sr1_table,sr2_table) %>% inner_join(.,x,by="AA_var")
# Number of variants bound per RE
# total variants bound per RE
counts <- rbind(sr1_table,sr2_table) %>% inner_join(.,x,by="AA_var") %>%
as_tibble() %>% dplyr::filter(.,!(RE_annotation_S == "Promiscuous")) %>%
dplyr::count(RE_annotation_S)
counts
# main fig.
p1 <- rbind(sr1_table,sr2_table) %>%
as_tibble() %>% filter(!(RE_annotation_S == "Promiscuous")) %>%
count(RE_annotation_S) %>%
mutate(RE_annotation_S = reorder(RE_annotation_S, desc(n))) %>%
ggplot(.,aes(x=RE_annotation_S,y=n)) +
geom_bar(stat="identity") +
scale_fill_manual(values="gray80") +
scale_y_continuous(limits = c(0,555)) +
theme_classic() +
ylab("Number of variants bound") +
theme(axis.title.x = element_blank(), axis.text.x = element_blank(),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold")) +
geom_text(data=counts,aes(x = RE_annotation_S, y=n, label=n),vjust=-0.5)
# main fig.
p1 <- rbind(sr1_table,sr2_table) %>%
as_tibble() %>% filter(!(RE_annotation_S == "Promiscuous")) %>%
dplyr::count(RE_annotation_S) %>%
mutate(RE_annotation_S = reorder(RE_annotation_S, desc(n))) %>%
ggplot(.,aes(x=RE_annotation_S,y=n)) +
geom_bar(stat="identity") +
scale_fill_manual(values="gray80") +
scale_y_continuous(limits = c(0,555)) +
theme_classic() +
ylab("Number of variants bound") +
theme(axis.title.x = element_blank(), axis.text.x = element_blank(),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold")) +
geom_text(data=counts,aes(x = RE_annotation_S, y=n, label=n),vjust=-0.5)
# main fig.
p1 <- rbind(sr1_table,sr2_table) %>%
as_tibble() %>% filter(!(RE_annotation_S == "Promiscuous")) %>%
dplyr::count(RE_annotation_S) %>%
dplyr::mutate(RE_annotation_S = reorder(RE_annotation_S, desc(n))) %>%
ggplot(.,aes(x=RE_annotation_S,y=n)) +
geom_bar(stat="identity") +
scale_fill_manual(values="gray80") +
scale_y_continuous(limits = c(0,555)) +
theme_classic() +
ylab("Number of variants bound") +
theme(axis.title.x = element_blank(), axis.text.x = element_blank(),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold")) +
geom_text(data=counts,aes(x = RE_annotation_S, y=n, label=n),vjust=-0.5)
# main fig.
p1 <- rbind(sr1_table,sr2_table) %>%
as_tibble() %>% dplyr::filter(!(RE_annotation_S == "Promiscuous")) %>%
dplyr::count(RE_annotation_S) %>%
dplyr::mutate(RE_annotation_S = reorder(RE_annotation_S, desc(n))) %>%
ggplot(.,aes(x=RE_annotation_S,y=n)) +
geom_bar(stat="identity") +
scale_fill_manual(values="gray80") +
scale_y_continuous(limits = c(0,555)) +
theme_classic() +
ylab("Number of variants bound") +
theme(axis.title.x = element_blank(), axis.text.x = element_blank(),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold")) +
geom_text(data=counts,aes(x = RE_annotation_S, y=n, label=n),vjust=-0.5)
rbind(sr1_table,sr2_table) %>%
as_tibble() %>% dplyr::filter(!(RE_annotation_S == "Promiscuous")) %>%
dplyr::count(RE_annotation_S) %>%
rbind(sr1_table,sr2_table) %>%
as_tibble() %>% dplyr::filter(!(RE_annotation_S == "Promiscuous")) %>%
dplyr::count(RE_annotation_S)
rbind(sr1_table,sr2_table) %>%
as_tibble() %>% dplyr::filter(.,!(RE_annotation_S == "Promiscuous")) %>%
dplyr::count(RE_annotation_S)
rbind(sr1_table,sr2_table) %>%
as_tibble() %>% dplyr::filter(.,!(RE_annotation_S == "Promiscuous")) %>%
dplyr::count(RE_annotation_S) %>%
dplyr::mutate(RE_annotation_S = reorder(RE_annotation_S, desc(n)))
# Number of variants bound per RE per BG
# Two plots, one for each background
s1 <- sr1_RE_counts %>%
ggplot(.,aes(x=RE,y=count_RE)) +
geom_bar(stat="identity",color="black", fill="#0398fc") +
scale_y_continuous(limits = c(0,50)) +
theme_classic() +
ylab("Number of variants bound") + xlab("") +
theme(axis.text.x = element_blank(),#axis.text.x = element_text(angle = 45, vjust = 1, hjust=1,size = 15),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold"),
legend.title=element_text(size=15),
legend.text = element_text(size=15)) +
geom_text(aes(x=RE,label=count_RE,y=count_RE),vjust=-0.5)
s2 <- sr2_RE_counts %>%
ggplot(.,aes(x=RE,y=count_RE)) +
geom_bar(stat="identity",color="black", fill="#fc9d03") +
scale_y_continuous(limits = c(0,1200)) +
theme_classic() +
ylab("Number of variants bound") + xlab("RE") +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1,size = 15),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold"),
legend.title=element_text(size=15),
legend.text = element_text(size=15)) +
geom_text(aes(x=RE,label=count_RE,y=count_RE),vjust=-0.5)
s1/s2
library(dplyr)
library(pheatmap)
library(reshape2)
library(RColorBrewer)
library(Biostrings)
library(igraph)
library(foreach)
library(doParallel)
library(sjmisc)
library(rgexf)
library(ggVennDiagram)
library(RVenn)
library(ggvenn)
library(venneuler)
library(patchwork)
library(ggplot2)
library(ggseqlogo)
calculate_pairwise_network_overlap <- function(df){
# keep only columns (REs) that are bound by at least one variant (remove unbound REs --> all NA columns)
not_all_na <- function(x) any(!is.na(x))
tmp <- dplyr::select(df,contains(c("AA_var","AncSR"))) %>% select_if(not_all_na)
#Variants bound to each RE
REBCs <- colnames(tmp)[-1]
REsets <- list()
for(i in 2:dim(tmp)[2]){
bound <- tmp[,i] %>% as_tibble() %>% mutate(mask = ifelse(!is.na(.[[1]]), TRUE, FALSE))
vars <- tmp$AA_var[bound$mask]
REsets[[REBCs[i-1]]] <- vars
}
#Pairwise combos (removing same-RE comparisons)
id <- expand.grid( REBCs , REBCs ) %>% filter(., Var1 != Var2)
#Calculate intersections and fractions of overlap
calc_union <- function(x,y){union(REsets[[x]],REsets[[y]])}
calc_intersect <- function(x,y){
r <- intersect(REsets[[x]],REsets[[y]])
if(identical(r, character(0))) r <- NA
r
}
calc_fraction_overlap_min <- function(x,y){
i <- calc_intersect(x,y)
f <- length(i[!is.na(i)])/min(c(length(REsets[[x]]),length(REsets[[y]]))) # the fraction of overlap is limited by the size of the smallest set
f
}
calc_fraction_overlap_union <- function(x,y){
i <- calc_intersect(x,y)
u <- calc_union(x,y)
f <- length(i[!is.na(i)])/length(u) # the fraction of overlap as AnB/AuB
f
}
id %>% as_tibble() %>% rowwise() %>%
dplyr::mutate(set1 = length(REsets[[Var1]]),
set2 = length(REsets[[Var2]]),
union = length(calc_union(Var1,Var2)),
intersect = length(calc_intersect(Var1,Var2)[!is.na(calc_intersect(Var1,Var2))]),
fraction_overlap_min = calc_fraction_overlap_min(Var1,Var2),
fraction_overlap_union = calc_fraction_overlap_union(Var1,Var2))
}
overlaps_sr1 <- calculate_pairwise_network_overlap(nodes_sr1_filt)
overlaps_sr2 <- calculate_pairwise_network_overlap(nodes_sr2_filt)
matrix_overlap_sr1 <- acast(overlaps_sr1, Var1~Var2, value.var="fraction_overlap_union")
matrix_overlap_sr1[lower.tri(matrix_overlap_sr1)] <- NA
matrix_overlap_sr2 <- acast(overlaps_sr2, Var1~Var2, value.var="fraction_overlap_union")
matrix_overlap_sr2[lower.tri(matrix_overlap_sr2)] <- NA
colors <- c("#3e3e40",rev(colorRampPalette(brewer.pal(11, "Spectral"))(50)))
pheatmap(matrix_overlap_sr1,cluster_rows=F, cluster_cols=F, na_col = "white",
clustering_method = "average",show_colnames = TRUE, show_rownames = TRUE,color = colors[1:45],
legend_breaks = c(0,0.05,0.1,0.15,0.2,0.25,0.3),legend = TRUE)
pheatmap(matrix_overlap_sr2,cluster_rows=F, cluster_cols=F, na_col = "white",
clustering_method = "average",show_colnames = TRUE, show_rownames = TRUE,color = colors,
legend_breaks = c(0,0.05,0.1,0.15,0.2,0.25,0.3), legend = TRUE)
hist(matrix_overlap_sr1)
hist(matrix_overlap_sr2)
hist(matrix_overlap_sr1, breaks = seq(0,0.34,0.02))
hist(matrix_overlap_sr2, breaks = seq(0,0.34,0.02))
load("/Users/santiagoherrera/Desktop/UChicago/Thornton_LAB/RH-RE_project/Data_all_RH-RE/Library_sequencing/NextSeq/220717_NextSeq_150PE_Rep1/Analysis/preliminary_analyses.RData")
setwd("/Users/santiagoherrera/Desktop/UChicago/Thornton_LAB/RH-RE_project/Data_all_RH-RE/Library_sequencing/NextSeq/220717_NextSeq_150PE_Rep1/Analysis")
library(dplyr)
library(pheatmap)
library(reshape2)
library(RColorBrewer)
library(Biostrings)
library(igraph)
library(foreach)
library(doParallel)
library(sjmisc)
library(rgexf)
library(ggVennDiagram)
library(RVenn)
library(ggvenn)
library(venneuler)
library(patchwork)
library(ggplot2)
library(ggseqlogo) # https://omarwagih.github.io/ggseqlogo/
# Import fluorescence data
f_data <- read.csv("./DMS_meanF_rep1_plusSpikeIns.csv") %>% filter(.,Count_total>=50)
f_nulls <- data[grep("[*]",data$AA_var),]
f_other <- data[-grep("[*]",data$AA_var),]
fraction_df <- dplyr::select(f_other,c("AA_var","REBC","meanF")) %>%
rowwise() %>%
dplyr::mutate(p_val = sum(f_nulls$meanF>=meanF)/length(f_nulls$meanF))
#=========================
# Identify active variants
#=========================
# Fraction of nulls >= meanF variant as a P-value:
f_nulls <- data[grep("[*]",data$AA_var),]
#=========================
# Identify active variants
#=========================
# Fraction of nulls >= meanF variant as a P-value:
f_nulls <- f_data[grep("[*]",f_data$AA_var),]
f_other <- f_data[-grep("[*]",f_data$AA_var),]
fraction_df <- dplyr::select(f_other,c("AA_var","REBC","meanF")) %>%
rowwise() %>%
dplyr::mutate(p_val = sum(f_nulls$meanF>=meanF)/length(f_nulls$meanF))
head(active_vars)
tmp <- active_vars %>% filter(.,REBC %in% c("AncSR1_REBC1","AncSR1_REBC3","AncSR2_REBC1","AncSR2_REBC3"))
unique(tmp$REBC)
tmp_ere <- tmp %>% filter(.,REBC %in% c("AncSR1_REBC3","AncSR2_REBC3"))
tmp_sre <- tmp %>% filter(.,REBC %in% c("AncSR1_REBC1","AncSR2_REBC1"))
tmp_ere
?gsub
tmp_ere %>% mutate(BG = gsub("_REBC3","",REBC))
tmp_ere <- tmp_ere %>% mutate(BG = gsub("_REBC3","",REBC))
tmp_sre <- tmp_sre %>% mutate(BG = gsub("_REBC1","",REBC))
tmp_both <- inner_join(x = tmp_ere,y=tmp_sre,by="AA_var") %>% select(.,c("AA_Var","meanF","BG"))
tmp_both <- inner_join(x = tmp_ere,y=tmp_sre,by="AA_var") %>% select(.,c("AA_var","meanF","BG"))
tmp_both <- inner_join(x = tmp_ere,y=tmp_sre,by="AA_var") %>% select(.,c(AA_var,meanF,BG))
tmp_both <- inner_join(x = tmp_ere,y=tmp_sre,by="AA_var") %>% dplyr::select(.,c("AA_var","meanF","BG"))
tmp_both <- inner_join(x = tmp_ere,y=tmp_sre,by="AA_var") %>% dplyr::select(.,AA_var,meanF,BG)
tmp_both <- inner_join(x = tmp_ere,y=tmp_sre,by="AA_var")
tmp_both
plot(tmp_both$meanF.x,tmp_both$meanF.y,pch=16,xlab="BG: AncSR1; RE: ERE",ylab="BG: AncSR2; RE: SRE")
tmp_ere <- tmp %>% filter(.,REBC %in% c("AncSR1_REBC3","AncSR2_REBC3")) %>%
mutate(BG = gsub("_REBC3","",REBC))
tmp_sre <- tmp %>% filter(.,REBC %in% c("AncSR1_REBC1","AncSR2_REBC1")) %>%
mutate(BG = gsub("_REBC1","",REBC))
sr1_ere <- tmp_ere %>% filter(.,BG=="AncSR1") %>% select(.,AA_var,meanF)
sr1_ere <- tmp_ere %>% filter(.,BG=="AncSR2") %>% select(.,AA_var,meanF)
sr1_ere <- tmp_ere %>% filter(.,BG=="AncSR1") %>% select(.,AA_var,meanF)
sr2_ere <- tmp_ere %>% filter(.,BG=="AncSR2") %>% select(.,AA_var,meanF)
sr1_sre <- tmp_sre %>% filter(.,BG=="AncSR1") %>% select(.,AA_var,meanF)
sr2_sre <- tmp_sre %>% filter(.,BG=="AncSR2") %>% select(.,AA_var,meanF)
plot(sr1_ere$meanF,sr2_ere$meanF,pch=16,xlab="AncSR1",ylab="AncSR2",main="ERE")
ere_both <- inner_join(sr1_ere,sr2_ere,by="AA_var")
sre_both <- inner_join(sr1_sre,sr2_sre,by="AA_var")
ere_both
plot(ere_both$meanF.x,ere_both$meanF.y,pch=16,xlab="AncSR1",ylab="AncSR2",main="ERE")
plot(sre_both$meanF.x,sre_both$meanF.y,pch=16,xlab="AncSR1",ylab="AncSR2",main="SRE")
setwd("/Users/santiagoherrera/Desktop")
write.csv(ere_both,file = "AncSR1_BG_vars.csv",quote = F)
write.csv(sre_both,file = "SRE_vars.csv",quote = F)
-0.6-(0-0.6)
0+(0-0.6)
perc_reads <- c(0.5311386,0.6084974,0.6751835,0.7320735,0.7797899,0.8193168,0.8516127,0.8778248,0.8991943,0.9163035,0.9301633,0.9413111,0.9519248,0.9592706,0.9651445,0.9700154,0.9740259,0.9775561,0.9803330,0.9826421,0.9846243,0.9862533,0.9876008,0.9887133,0.9896307,0.9904135,0.9910934,0.9917535,0.9923073,0.9927959,0.9932171)
mean_error <- c(-0.001365818,-0.001555202,-0.001855371,-0.002165824,-0.002116223,-0.002309023,-0.002569058,-0.003327030,-0.002656506,-0.002627584,-0.002683280,-0.002779987,-0.002573599,-0.002486326,-0.002438821,-0.002446122,-0.002362204,-0.002380594,-0.002197379,-0.002059654,-0.001982174,-0.001946529,-0.001836772,-0.001740750,-0.001684376,-0.001600747,-0.002233317,-0.002512129,-0.001947856,-0.001558087,-0.001177475)
plot(seq(0,3,0.1), mean_error, type="l", col = "black",xlab="k value",ylab="Mean Error")              # Create first plot
plot(seq(0,3,0.1), mean_error, type="l", col = "black",xlab="k value",ylab="Mean Error",lwd=2)              # Create first plot
plot(seq(0,3,0.1), perc_reads, type="l", col = "red",              # Create second plot without axes
axes = FALSE, xlab = "", ylab = "",lwd=2)
plot(seq(0,3,0.1), mean_error, type="l", col = "black",xlab="k value",ylab="Mean Error",lwd=2)              # Create first plot
par(new = TRUE)
plot(seq(0,3,0.1), perc_reads, type="l", col = "red",              # Create second plot without axes
axes = FALSE, xlab = "", ylab = "",lwd=2)
axis(side = 4, at = pretty(range(perc_reads)))      # Add second axis
mtext("% reads retained", side = 4, line = 3)             # Add second axis label
par(mar = c(5, 4, 4, 4) + 0.3)
plot(seq(0,3,0.1), mean_error, type="l", col = "black",xlab="k value",ylab="Mean Error",lwd=2)              # Create first plot
par(new = TRUE)
plot(seq(0,3,0.1), perc_reads, type="l", col = "red",              # Create second plot without axes
axes = FALSE, xlab = "", ylab = "",lwd=2)
axis(side = 4, at = pretty(range(perc_reads)))      # Add second axis
mtext("% reads retained", side = 4, line = 3)             # Add second axis label
par(mar = c(5, 4, 4, 4) + 0.3)
plot(seq(0,3,0.1), mean_error, type="l", col = "black",xlab="k value",ylab="Mean Error",lwd=2)              # Create first plot
par(new = TRUE)
plot(seq(0,3,0.1), perc_reads, type="l", col = "red",              # Create second plot without axes
axes = FALSE, xlab = "", ylab = "",lwd=2)
axis(side = 4, at = pretty(range(perc_reads)),col="red")      # Add second axis
mtext("% reads retained", side = 4, line = 3,col="red")             # Add second axis label
-0.0726-(0.0690-(-0.0726))
0.0690+(0.0690-(-0.0726))
##BayesTraits pairs: site 111
data111 <- read.table("../data/BayesTraits/s111_out_BT_restricted_rates_rootedTree.txt")
setwd("/Users/santiagoherrera/Desktop/PROYECTOS/ATPase_Project/ASR/a1-3_v2/GitHub_repo/ATPase_convergence/notebooks")
data111 <- read.table("../data/BayesTraits/s111_out_BT_restricted_rates_rootedTree.txt")
colnames(data111) <- c("file","LnL_null","LnL_alt")
LRS <- c()
pval <- c()
for(i in 1:dim(data111)[1]){
#LRS = 2*(unrestricted model – restricted model)
LRS <- c(LRS,(2*((data111[i,2]-data111[i,3]))))
pval <- c(pval,pchisq(q=(2*((data111[i,2]-data111[i,3]))),df=2,lower.tail = F))
}
data111$LRS <- LRS
data111$pval <- pval
data111$pval_bonf <- p.adjust(p = data111$pval,method = "bonferroni")
data111$logP <- -log10(data111$pval)
data111$alignment_pos <-  as.numeric(stringr::str_extract(data111$file,"(_V[0-9]+\\.)") %>% gsub("_","",.) %>% gsub("\\.","",.) %>%
gsub("V","",.))
library(dplyr)
data111 <- read.table("../data/BayesTraits/s111_out_BT_restricted_rates_rootedTree.txt")
colnames(data111) <- c("file","LnL_null","LnL_alt")
LRS <- c()
pval <- c()
for(i in 1:dim(data111)[1]){
#LRS = 2*(unrestricted model – restricted model)
LRS <- c(LRS,(2*((data111[i,2]-data111[i,3]))))
pval <- c(pval,pchisq(q=(2*((data111[i,2]-data111[i,3]))),df=2,lower.tail = F))
}
data111$LRS <- LRS
data111$pval <- pval
data111$pval_bonf <- p.adjust(p = data111$pval,method = "bonferroni")
data111$logP <- -log10(data111$pval)
data111$alignment_pos <-  as.numeric(stringr::str_extract(data111$file,"(_V[0-9]+\\.)") %>% gsub("_","",.) %>% gsub("\\.","",.) %>%
gsub("V","",.))
hist(data111$LRS,breaks = 50)
abline(v=qchisq(0.05,df=2,lower.tail = F),col="red")
hist(data111$logP,breaks = 50,main="-log(P) association with 111")
abline(v=quantile(data111$logP,0.95),col="red")
data122 <- read.table("../data/BayesTraits/s122_out_BT_restricted_rates_rootedTree.txt")
colnames(data122) <- c("file","LnL_null","LnL_alt")
LRS <- c()
pval <- c()
for(i in 1:dim(data122)[1]){
#LRS = 2*(unrestricted model – restricted model)
LRS <- c(LRS,(2*((data122[i,2]-data122[i,3]))))
pval <- c(pval,pchisq(q=(2*((data122[i,2]-data122[i,3]))),df=2,lower.tail = F))
}
data122$LRS <- LRS
data122$pval <- pval
data122$pval_bonf <- p.adjust(p = data122$pval,method = "bonferroni")
data122$logP <- -log10(data122$pval)
data122$alignment_pos <-  as.numeric(stringr::str_extract(data122$file,"(_V[0-9]+\\.)") %>% gsub("_","",.) %>% gsub("\\.","",.) %>%
gsub("V","",.))
#hist(data122$LRS,breaks = 50)
#abline(v=qchisq(0.05,df=2,lower.tail = F),col="red")
hist(data122$logP,breaks = 50,main="-log(P) association with 122")
abline(v=quantile(data122$logP,0.95),col="red")
match_site <- function(table){
sites <- c()
## e.g. outliers table
for(i in 1:dim(table)[1]){
position <- table[i,8]
site <- NA
if(position >= 14 && position <= 28) site <- position - 13
if(position >= 48 && position <= 137) site <- position - 23
if(position >= 139) site <- position - 24
sites <- c(sites,site)
}
return(sites)
}
# Extract outliers
outliers111 <- data111[(data111$logP > quantile(data111$logP,0.95)),]
outliers122 <- data122[(data122$logP > quantile(data122$logP,0.95)),]
# Match sites with sheep reference sequence positions
outliers111$site <- match_site(outliers111)
outliers122$site <- match_site(outliers122)
data111$site <- match_site(data111)
data122$site <- match_site(data122)
spatial_df_111 <- read.table("../data/pymol/distance_pairs111_3b8e.out",header = TRUE)
spatial_df_122 <- read.table("../data/pymol/distance_pairs122_3b8e.out",header = TRUE)
spatial_df_111 <- read.table("../data/pymol/distance_pairs111_3b8e.out",header = TRUE) %>% .[!is.na(.$distance),]
spatial_df_111
data111$site <- match_site(data111)
data122$site <- match_site(data122)
## Spatial enrichment analysis: using the pairwise distance in 3D structre between each pair,
## check whether top 5% sites are clustered in space.
spatial_df_111 <- read.table("../data/pymol/distance_pairs111_3b8e.out",header = TRUE) %>% .[!is.na(.$distance),]
spatial_df_122 <- read.table("../data/pymol/distance_pairs122_3b8e.out",header = TRUE) %>% .[!is.na(.$distance),]
spatial_df_111$site <- spatial_df_111$site2
spatial_df_122$site <- spatial_df_122$site2
## combine BayesTraits output with spatial information for each site
spatial_df_111 <- spatial_df_111[spatial_df_111$site2 %in% data111$site,]
spatial_df_122 <- spatial_df_122[spatial_df_122$site2 %in% data122$site,]
# Top 5% sites from BayesTraits for each focal site
BT.111.sites <- data111[!(data111$site<68),] %>% arrange(.,desc(logP)) %>% slice(.,1:(0.05*360)) %>% select(site) # 360 sites * 0.05 = 18 top 5% sites
BT.122.sites <- data122[!(data122$site<68),] %>% arrange(.,desc(logP)) %>% slice(.,1:(0.05*360)) %>% select(site)
spatial_df_122
data111[!(data111$site<68),]
data111[!(data111$site<68),] %>% arrange(.,desc(logP))
library(dplyr)
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
# Top 5% sites from BayesTraits for each focal site
# Exclude poorly aligned region (1-68 amino acids)
# Extract top 5% --> # 360 sites * 0.05 = 18 top 5% sites
BT.111.sites <- data111[!(data111$site<68),] %>% arrange(.,desc(logP)) %>% slice(.,1:(0.05*360)) %>% select(site)
df=data.frame(id=c(11,22,33,44,55),
name=c("spark","python","R","jsp","java"),
price=c(144,NA,321,567,567),
publish_date= as.Date(
c("2007-06-22", "2004-02-13", "2006-05-18",
"2010-09-02","2007-07-20"))
)
# Load dplyr library
library(dplyr)
# Using arrange in ascending order
df2 <- df %>% arrange(price)
df2
data111[!(data111$site<68),] %>% arrange(.,desc(logP),relax=F)
rlang::last_error()
data111[!(data111$site<68),] %>% arrange(.,desc(logP),.locale = NULL)
?arrange
data(mtcars)
arrange(mtcars, cyl, disp)
?order
# Top 5% sites from BayesTraits for each focal site
# Exclude poorly aligned region (1-68 amino acids)
# Extract top 5% --> # 360 sites * 0.05 = 18 top 5% sites
ordered_row_logP_111 <- order(data111[, "logP"],decreasing =TRUE)
ordered_row_logP_111
ordered_row_logP_122 <- order(data122[, "logP"],decreasing =TRUE)
BT.111.sites <- data111[!(data111$site<68) & ordered_row_logP_111,] %>% slice(.,1:(0.05*360)) %>% select(site)
BT.111.sites <- data111[!(data111$site<68) && ordered_row_logP_111,] %>% slice(.,1:(0.05*360)) %>% select(site)
BT.122.sites <- data122[!(data122$site<68) && ordered_row_logP_122,] %>% slice(.,1:(0.05*360)) %>% select(site)
med_111 <- median(spatial_df_111[spatial_df_111$site2 %in% BT.111.sites$site,]$distance)
med_122 <- median(spatial_df_122[spatial_df_122$site2 %in% BT.122.sites$site,]$distance)
null_111 <- c()
null_122 <- c()
for(i in 1:10000){
s111 <- sample(spatial_df_111$distance,18,replace = F)
s122 <- sample(spatial_df_122$distance,18,replace = F)
null_111 <- c(null_111,median(s111))
null_122 <- c(null_122,median(s122))
}
p111 <- sum(null_111<=med_111)/10000
p122 <- sum(null_122<=med_122)/10000
hist(null_111,xlab="Ditance to 111",breaks = 30,xlim = c(25,100))
abline(v=med_111,col="red")
p111
p122
data111$site <- match_site(data111)
data122$site <- match_site(data122)
outliers111$site <- match_site(outliers111)
outliers122$site <- match_site(outliers122)
spatial_df_111 <- read.table("../data/pymol/distance_pairs111_3b8e.out",header = TRUE) %>% .[!is.na(.$distance),]
spatial_df_122 <- read.table("../data/pymol/distance_pairs122_3b8e.out",header = TRUE) %>% .[!is.na(.$distance),]
spatial_df_111$site <- spatial_df_111$site2
spatial_df_122$site <- spatial_df_122$site2
spatial_BT_111top5 <- inner_join(outliers111,spatial_df_111,by="site")
spatial_BT_122top5 <- inner_join(outliers122,spatial_df_122,by="site")
spatial_BT_111 <- inner_join(data111,spatial_df_111,by="site")
spatial_BT_122 <- inner_join(data122,spatial_df_122,by="site")
spatial_enrichment <- function(df,outlier_df){
#median distance to focal site in outliers
med_dist <- median(outlier_df$distance)
bootstrap_distances <- c()
for(i in 1:1000){
sites <- sample(df$site,size = dim(outlier_df)[1],replace = TRUE)
t2 <- df[(df$site %in% sites),]
bootstrap_distances <- c(bootstrap_distances, median(t2$distance))
}
pval <- sum(bootstrap_distances <= med_dist)/length(bootstrap_distances)
print(paste("median distance of top 5% sites to site: ", med_dist," | Pval = ",pval))
return(bootstrap_distances)
}
null_dist_111 <- spatial_enrichment(spatial_BT_111,spatial_BT_111top5)
null_dist_122 <- spatial_enrichment(spatial_BT_122,spatial_BT_122top5)
hist(null_dist_111,main="median 3D distance to site 111",breaks = 30,xlab="median distance (Angstroms)",
xlim=c(25,100))
abline(v=25.1018445,col="red")
hist(null_dist_122,main="median 3D distance to site 122",breaks = 30,xlab="median distance (Angstroms)")
abline(v=34.0234085,col="red")
remove.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("rlang")
install.packages("rlang")
install.packages("pillas")
install.packages("pillar")
install.packages("dplyr")
